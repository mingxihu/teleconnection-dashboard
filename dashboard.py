import streamlit as st
from datetime import datetime, timedelta
import requests
import io
import re
from pypdf import PdfReader
import pandas as pd
import json
import os
from streamlit_autorefresh import st_autorefresh

# === 1. é¡µé¢å…¨å±€é…ç½® ===
st.set_page_config(
    page_title="Climateâ€“Natural Gas Analytics",
    page_icon="âš›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# === [é…ç½®] è‡ªåŠ¨åˆ·æ–° (1å°æ—¶) ===
st_autorefresh(interval=3600000, key="data_refresh_key")

# === 2. æ ·å¼ä¼˜åŒ– (CSS) ===
st.markdown("""
    <style>
    [data-testid="stSidebar"] { background-color: #f8f9fa; }

    /* ä¾§è¾¹æ é¡¶éƒ¨ç´§å‡‘æ¨¡å¼ */
    section[data-testid="stSidebar"] .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }

    /* Tabs æ ·å¼ */
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stTabs [data-baseweb="tab"] {
        height: 45px; white-space: pre-wrap; padding: 8px 16px; 
        background-color: #fff; border-radius: 4px; border: 1px solid #e0e0e0;
    }
    .stTabs [aria-selected="true"] {
        background-color: #e3f2fd; border-left: 4px solid #1565c0; color: #1565c0;
    }

    /* [æ ¸å¿ƒé¢œè‰²ç»Ÿä¸€] Bullish (Negative/Cold) = Green; Bearish (Positive/Warm) = Red */
    .tag-minus {
        background-color: #e8f5e9; color: #2e7d32; /* ç»¿è‰²: è´Ÿç›¸ä½/å¯’å†·/åˆ©å¤š */
        padding: 4px 12px; border-radius: 6px; font-weight: 700; font-size: 1.1em; 
        border: 1px solid #c8e6c9; display: inline-block; margin: 4px 0;
    }
    .tag-plus {
        background-color: #e8f5e9; color: #2e7d32; /* [FIXED] ç»¿è‰²: æ­£ç›¸ä½/PNA/åˆ©å¤š */
        padding: 4px 12px; border-radius: 6px; font-weight: 700; font-size: 1.1em;
        border: 1px solid #c8e6c9; display: inline-block; margin: 4px 0;
    }

    .tag-bear {
        background-color: #ffebee; 
        color: #c62828;               /* çº¢è‰²ï¼šæš–å†¬/åˆ©ç©º */
        padding: 4px 12px; 
        border-radius: 6px; 
        font-weight: 700; 
        font-size: 1.1em;
        border: 1px solid #ffcdd2; 
        display: inline-block; 
        margin: 4px 0;
    }

    .tag-neutral {
        background-color: #f5f5f5; color: #616161; 
        padding: 4px 12px; border-radius: 6px; font-weight: 700; font-size: 1.1em;
        border: 1px solid #e0e0e0; display: inline-block; margin: 4px 0;
    }

    /* ä¿¡å·æ¡†æ ·å¼ */
    .signal-box-bull {
        background-color: #fff; border-left: 4px solid #c62828;
        padding: 16px; border-radius: 8px; margin-top: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        border: 1px solid #f0f0f0;
    }

    /* å†³ç­–çŸ©é˜µæ’ç‰ˆæ ·å¼ */
    .decision-content {
        margin-top: 10px;
        font-size: 0.95em;
        line-height: 1.6;
    }
    .decision-label {
        font-weight: 700; 
        color: #212121;
        display: block; 
        margin-top: 10px;
        margin-bottom: 4px;
    }

    .zoom-img:hover { opacity: 0.9; cursor: zoom-in; transition: 0.3s; }
    </style>
""", unsafe_allow_html=True)

# === 3. æ ¸å¿ƒæ•°æ®æº ===
IMG_URLS = {
    "AO": "https://www.cpc.ncep.noaa.gov/products/precip/CWlink/daily_ao_index/ao.gefs.sprd2.png",
    "NAO": "https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/nao.gefs.sprd2.png",
    "PNA": "https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/pna.gefs.sprd2.png",
    "LANINA": "https://www.cpc.ncep.noaa.gov/products/analysis_monitoring/lanina/enso_evolution-status-fcsts-web.pdf"
}

LINKS = {
    "NOAA_HOME": "https://www.cpc.ncep.noaa.gov/",
    "YAHOO_NG": "https://finance.yahoo.com/quote/NG=F",
    "YAHOO_EQT": "https://finance.yahoo.com/quote/EQT",
    "YAHOO_BOIL": "https://finance.yahoo.com/quote/BOIL",
    "YAHOO_CSX": "https://finance.yahoo.com/quote/CSX",
    "YAHOO_UNP": "https://finance.yahoo.com/quote/UNP",
    "YAHOO_UAL": "https://finance.yahoo.com/quote/UAL",
}


# === è¾…åŠ©å‡½æ•°å®šä¹‰ (å¿…é¡»åœ¨è°ƒç”¨å‰) ===

def clickable_image_html(img_url, alt_text):
    html_code = f'''
    <a href="{img_url}" target="_blank">
        <img src="{img_url}" class="zoom-img" style="width:100%; border-radius:5px; border:1px solid #ddd;" alt="{alt_text}">
    </a>
    '''
    st.markdown(html_code, unsafe_allow_html=True)


def signal_card(title, dynamics, impact, signal_text):
    html = f"""
<div class="signal-box-bull">
    <div style="font-size: 1.15em; font-weight: bold; margin-bottom: 12px; color: #212121;">{title}</div>
    <div style="margin-bottom: 8px; color: #424242;">
        ğŸŒªï¸ <b>åŠ¨åŠ›å­¦:</b> {dynamics}
    </div>
    <div style="margin-bottom: 12px; color: #424242;">
        ğŸ¥¶ <b>å½±å“:</b> {impact.replace('**', '')} 
    </div>
    <div style="background-color: #ffebee; padding: 8px; border-radius: 4px; color: #c62828; font-weight: bold;">
        ğŸ”¥ ä¿¡å·: {signal_text}
    </div>
</div>
"""
    st.markdown(html, unsafe_allow_html=True)


# === æå–æœ¬åœ°å†å²æ•°æ®æœ€æ–°è¡Œ (ä¾› NCRI å’Œ Tab å±•ç¤ºä½¿ç”¨) ===
def load_latest_climate_data():
    """ä»æœ¬åœ° CSV æ–‡ä»¶è¯»å–æœ€æ–°ä¸€è¡Œçš„ AO/NAO/PNA æ•°æ®ã€‚"""
    HISTORY_FILE = "history_weather.csv"
    try:
        if not os.path.exists(HISTORY_FILE):
            return None
        df = pd.read_csv(HISTORY_FILE)
        return df.iloc[-1].to_dict()
    except Exception as e:
        return None


# === è¾…åŠ©å‡½æ•° - æ˜¾ç¤ºå½“å‰æ°”è±¡æŒ‡æ ‡çš„å€¼ (ä¾› Tab ä½¿ç”¨) ===
def display_current_index_value(index_name):
    global latest_data

    if latest_data:
        obs_val = latest_data.get(f'{index_name}_Obs')
        d7_val = latest_data.get(f'{index_name}_Day7')
        d10_val = latest_data.get(f'{index_name}_Day10')

        is_nao_ao = index_name in ["NAO", "AO"]

        def get_style(value):
            if value is None: return "color: #888;", "-"
            is_positive = value > 0
            if is_nao_ao:
                is_bullish = not is_positive
            else:
                is_bullish = is_positive
            color = "#2e7d32" if is_bullish else "#c62828"  # Green or Red
            arrow = "â–²" if is_bullish else "â–¼"
            return f"color: {color};", arrow

        obs_style, obs_arrow = get_style(obs_val)
        d7_style, d7_arrow = get_style(d7_val)
        d10_style, d10_arrow = get_style(d10_val)

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown(f"**ä»Šæ—¥å®å†µ (Observed):**")
            st.markdown(
                f"<span style='font-size: 1.8em; font-weight: bold; {obs_style}'>{obs_arrow} {obs_val:.3f}</span>",
                unsafe_allow_html=True)
        with col2:
            st.markdown(f"**7å¤©é¢„æµ‹ (Forecast Day 7):**")
            st.markdown(f"<span style='font-size: 1.8em; font-weight: bold; {d7_style}'>{d7_arrow} {d7_val:.3f}</span>",
                        unsafe_allow_html=True)
        with col3:
            st.markdown(f"**10å¤©é¢„æµ‹ (Forecast Day 10):**")
            st.markdown(
                f"<span style='font-size: 1.8em; font-weight: bold; {d10_style}'>{d10_arrow} {d10_val:.3f}</span>",
                unsafe_allow_html=True)
        st.markdown("---")
    else:
        st.warning("âš ï¸ æ•°æ®åº“å°šæœªæ›´æ–°ï¼Œè¯·è¿è¡Œ 'climate_collector.py' è·å–æ•°æ®ã€‚")


# === HDD æ•°æ®æŠ“å–å‡½æ•° (CSVç‰ˆ) ===
# [ä¿®æ”¹ç‚¹] ä½¿ç”¨ @st.cache_data æ›¿æ¢ @st.cache
@st.cache_data(ttl=60)
def get_gas_hdd():
    csv_file = "history_hdd.csv"
    try:
        if not os.path.exists(csv_file):
            return None, None

        df = pd.read_csv(csv_file)
        if df.empty: return None, None

        latest = df.iloc[-1]
        source_date = latest.get("Source_Date", "N/A")

        data_bag = {
            "New England": {
                "actual": latest.get("NE_Actual", 0),
                "dev_normal": latest.get("NE_Dev_Norm", 0),
                "dev_last_year": latest.get("NE_Dev_Year", 0)
            },
            "Middle Atlantic": {
                "actual": latest.get("MA_Actual", 0),
                "dev_normal": latest.get("MA_Dev_Norm", 0),
                "dev_last_year": latest.get("MA_Dev_Year", 0)
            },
            "Midwest": {
                "actual": latest.get("MW_Actual", 0),
                "dev_normal": latest.get("MW_Dev_Norm", 0),
                "dev_last_year": latest.get("MW_Dev_Year", 0)
            },
            "US Total": {
                "actual": latest.get("US_Actual", 0),
                "dev_normal": latest.get("US_Dev_Norm", 0),
                "dev_last_year": latest.get("US_Dev_Year", 0)
            }
        }
        return data_bag, source_date
    except Exception as e:
        return None, None


# === ENSO æŠ¥å‘Šè§£æ (ä¿æŒåŸæ ·) ===
# [ä¿®æ”¹ç‚¹] ä½¿ç”¨ @st.cache_data æ›¿æ¢ @st.cache
@st.cache_data(ttl=3600)
def get_enso_summary(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        if response.status_code == 200:
            f = io.BytesIO(response.content)
            reader = PdfReader(f)
            raw_text = ""
            for i in range(min(5, len(reader.pages))):
                page_text = reader.pages[i].extract_text()
                if "ENSO Alert System Status" in page_text:
                    raw_text = page_text
                    break
            if not raw_text: return {"status": "æœªæ‰¾åˆ° Summary", "body": []}

            status_line = "Unknown"
            if "ENSO Alert System Status:" in raw_text:
                parts = raw_text.split("ENSO Alert System Status:", 1)
                temp = parts[1].strip()
                status_line = temp.split("\n")[0]
                raw_text = parts[1].replace(status_line, "", 1)

            if "* Note" in raw_text:
                raw_text = raw_text.split("* Note", 1)[0]
            elif "Note:" in raw_text:
                raw_text = raw_text.split("Note:", 1)[0]

            clean_text = raw_text.replace("\n", " ")
            clean_text = re.sub(' +', ' ', clean_text).strip()
            sentences = clean_text.split('. ')
            formatted_sentences = [s.strip() + "." for s in sentences if len(s) > 5]
            return {"status": status_line, "body": formatted_sentences}
    except Exception as e:
        return {"status": "Error", "body": [str(e)]}
    return {"status": "Error", "body": []}


# === EIA æ•°æ®è§£æ (CSVç‰ˆ - æç®€è¡Œå) ===
# [ä¿®æ”¹ç‚¹] ä½¿ç”¨ @st.cache_data æ›¿æ¢ @st.cache
@st.cache_data(ttl=60)
def load_eia_total():
    csv_file = "history_storage.csv"
    try:
        if not os.path.exists(csv_file):
            return None, None

        df_csv = pd.read_csv(csv_file)
        if df_csv.empty: return None, None

        latest = df_csv.iloc[-1]

        report_date_str = latest.get("Report_Date", "")
        try:
            current_date_obj = datetime.strptime(report_date_str, "%Y-%m-%d")
            week_ago_obj = current_date_obj - timedelta(days=7)
            curr_fmt = current_date_obj.strftime("%m/%d/%y")
            prev_fmt = week_ago_obj.strftime("%m/%d/%y")
        except:
            curr_fmt = "Current"
            prev_fmt = "Prev Week"

        labels = [
            curr_fmt,  # 1. æœ¬å‘¨
            prev_fmt,  # 2. ä¸Šå‘¨
            "Net Chg",  # 3. ç®€å†™
            "Year Ago",  # 4. ç®€å†™
            "vs Year %",  # 5. ç®€å†™
            "5-Yr Avg",  # 6. ç®€å†™
            "vs 5Yr %"  # 7. ç®€å†™
        ]

        def calc_pct(curr, base):
            try:
                if base is None or base == 0: return None
                return ((curr - base) / base) * 100
            except:
                return None

        regions_to_extract = [
            ("Total", "Total"),
            ("East", "East"),
            ("Midwest", "Midwest"),
            ("SouthCentral", "S.Central")
        ]

        rows = []
        for prefix, display_name in regions_to_extract:
            stock = latest.get(f"{prefix}_Stock")
            net = latest.get(f"{prefix}_Net_Change")
            yr = latest.get(f"{prefix}_Year_Ago")
            avg = latest.get(f"{prefix}_5Yr_Avg")

            prev = stock - net if (stock is not None and net is not None) else None

            row = {
                "Region": display_name,
                labels[0]: stock,
                labels[1]: prev,
                labels[2]: net,
                labels[3]: yr,
                labels[4]: calc_pct(stock, yr),
                labels[5]: avg,
                labels[6]: calc_pct(stock, avg)
            }
            rows.append(row)

        df_display = pd.DataFrame(rows).set_index("Region")

        return df_display, report_date_str

    except Exception as e:
        return None, None


# === 4. ä¾§è¾¹æ å¯¼èˆª ===
with st.sidebar:

    # [æ–°å¢] è§†å›¾åˆ‡æ¢ (æ ¸å¿ƒåŠŸèƒ½)
    view_mode = st.radio(
        "",
        ["ğŸš€ å®æ—¶ç›‘æ§", "ğŸ“… å†å²å›æº¯"],
        index=0
    )
    st.markdown("---")

    # ---- HDD æ•°æ®æ¿å— ----
    st.subheader("ğŸ”¥ å®é™…ç‡ƒçƒ§éœ€æ±‚ (HDD)")

    hdd_data, hdd_date = get_gas_hdd()

    if hdd_data:
        def show_dual_metric(col, label, data):
            actual = data.get('actual', '-')
            dev_norm = data.get('dev_normal', 0)
            dev_year = data.get('dev_last_year', 0)

            with col:
                st.metric(
                    label=label,
                    value=f"{actual}",
                    delta=f"{dev_norm} (Norm)",
                    delta_color="normal"
                )
                color = "#2e7d32" if dev_year > 0 else "#c62828"
                arrow = "â–²" if dev_year > 0 else "â–¼"
                if dev_year == 0:
                    color = "#666"
                    arrow = "-"

                st.markdown(
                    f"""<div style="margin-top: -15px; font-size: 0.85em; color: #555;">vs Year: <span style="color: {color}; font-weight: bold;">{arrow} {dev_year}</span></div>""",
                    unsafe_allow_html=True)


        hd_col1, hd_col2 = st.columns(2)
        show_dual_metric(hd_col1, "New England", hdd_data.get('New England', {}))
        show_dual_metric(hd_col2, "Mid-Atlantic", hdd_data.get('Middle Atlantic', {}))
        show_dual_metric(hd_col1, "Midwest", hdd_data.get('Midwest', {}))
        show_dual_metric(hd_col2, "US Total", hdd_data.get('US Total', {}))

        st.caption(f"ğŸ“… Source Updated: {hdd_date}")
        st.caption("[NOAA HDD Data](https://www.cpc.ncep.noaa.gov/products/analysis_monitoring/cdus/degree_days/)")

    else:
        st.warning("HDD æ•°æ®æš‚ä¸å¯ç”¨")

    st.markdown("---")

    # ---- EIA æ¨¡å— ----
    st.markdown("### ğŸ¦ EIA å¤©ç„¶æ°”åº“å­˜")
    try:
        eia_df, eia_date = load_eia_total()

        if eia_df is not None:
            tdf = eia_df.T


            def num_fmt(x):
                if pd.isna(x): return ""
                v = float(x)
                if abs(v - round(v)) < 1e-6: return f"{int(round(v)):,d}"
                return f"{v:.1f}".rstrip("0").rstrip(".")


            highlight_rows = ["Net Chg", "vs Year %", "vs 5Yr %"]


            def highlight_style(df):
                styles = pd.DataFrame('font-weight: bold;', index=df.index, columns=df.columns)
                for idx in df.index:
                    if idx in highlight_rows:
                        for col in df.columns:
                            val = df.loc[idx, col]
                            base = 'font-weight: bold; background-color: #fff3cd;'
                            if pd.notna(val):
                                if val < 0:
                                    styles.loc[idx, col] = base + 'color: #2e7d32;'
                                elif val > 0:
                                    styles.loc[idx, col] = base + 'color: #c62828;'
                                else:
                                    styles.loc[idx, col] = base + 'color: black;'
                            else:
                                styles.loc[idx, col] = base + 'color: black;'
                return styles


            st.dataframe(tdf.style.format(num_fmt).apply(highlight_style, axis=None))
            st.caption(f"ğŸ“… Source Updated: {eia_date}")

        else:
            st.write("æœªæ‰¾åˆ° EIA æ•°æ®ã€‚")
    except Exception as e:
        st.warning(f"EIA Error: {e}")

    st.caption("[EIA Weekly Report](https://ir.eia.gov/ngs/ngs.html)")
    st.markdown("---")

    # ---- å…¶å®ƒå¯¼èˆª ----
    st.markdown("### ğŸ›ï¸ å®˜æ–¹æ•°æ®æº")
    st.markdown(f"- [NOAA CPC æ°”å€™é¢„æµ‹]({LINKS['NOAA_HOME']})")
    st.markdown(f"- [**ENSO / æ‹‰å°¼å¨œå‘¨æŠ¥**]({IMG_URLS['LANINA']})")

    st.markdown("### âš¡ èƒ½æºè¡Œæƒ…")
    st.markdown(f"- [**NG=F** (å¤©ç„¶æ°”æœŸè´§)]({LINKS['YAHOO_NG']})")
    st.markdown(f"- [**EQT** (ç”Ÿäº§å•†è‚¡ä»·)]({LINKS['YAHOO_EQT']})")
    st.markdown(f"- [**BOIL** (2å€åšå¤šETF)]({LINKS['YAHOO_BOIL']})")

    st.markdown("### ğŸš‚ äº¤é€šè¿è¾“")
    st.markdown(f"- [**CSX** (ç¾ä¸œé“è·¯)]({LINKS['YAHOO_CSX']})")
    st.markdown(f"- [**UNP** (è”åˆå¤ªå¹³æ´‹)]({LINKS['YAHOO_UNP']})")
    st.markdown(f"- [**UAL** (è”åˆèˆªç©º)]({LINKS['YAHOO_UAL']})")

    st.caption("Geoscience & Financial Analytics MH")

# ==========================================
# 5. ä¸»é€»è¾‘æ§åˆ¶ (Live vs History)
# ==========================================

if view_mode == "ğŸš€ å®æ—¶ç›‘æ§":
    # === åŸæœ¬çš„ä¸»ç•Œé¢ä»£ç  ===
    st.title("âš›ï¸ å¤©ç„¶æ°”æ°”è±¡åˆ†æç»ˆç«¯")
    st.caption(
        f"**æ•°æ®æ›´æ–° (Last Updated):** `{datetime.now().astimezone().strftime('%Y-%m-%d %H:%M %Z')}`")
    st.markdown("---")

    latest_data = load_latest_climate_data()


    # [æ–°å¢] è¾…åŠ©å‡½æ•° - æ˜¾ç¤ºå½“å‰æ°”è±¡æŒ‡æ ‡çš„å€¼
    def display_current_index_value(index_name):
        if latest_data:
            # è·å– CSV ä¸­çš„å€¼
            obs_val = latest_data.get(f'{index_name}_Obs')
            d7_val = latest_data.get(f'{index_name}_Day7')
            d10_val = latest_data.get(f'{index_name}_Day10')

            # === æ ¸å¿ƒé¢œè‰²é€»è¾‘ ===
            is_nao_ao = index_name in ["NAO", "AO"]

            def get_style(value):
                if value is None: return "color: #888;", "-"
                is_positive = value > 0
                if is_nao_ao:
                    is_bullish = not is_positive
                else:
                    is_bullish = is_positive
                color = "#2e7d32" if is_bullish else "#c62828"
                arrow = "â–²" if is_bullish else "â–¼"
                return f"color: {color};", arrow

            obs_style, obs_arrow = get_style(obs_val)
            d7_style, d7_arrow = get_style(d7_val)
            d10_style, d10_arrow = get_style(d10_val)

            html_card = f"""
            <div style='
                margin-top: 15px; 
                border: 1px solid #e0e0e0; 
                border-radius: 6px; 
                padding: 8px; 
                background-color: #f8f8f8;
                display: flex; 
                justify-content: space-around;
                text-align: center;
                font-size: 0.95em;
            '>
                <div style='flex:1; border-right: 1px solid #eee;'>
                    <span style='font-weight: bold; color: #555;'>OBSERVED (Today)</span><br>
                    <span style='font-size: 1.3em; {obs_style}; font-weight: bold;'>{obs_val:.3f}</span>
                </div>
                <div style='flex:1; border-right: 1px solid #eee;'>
                    <span style='font-weight: bold; color: #555;'>DAY 7 FORECAST</span><br>
                    <span style='font-size: 1.3em; {d7_style}; font-weight: bold;'>{d7_val:.3f}</span>
                </div>
                <div style='flex:1;'>
                    <span style='font-weight: bold; color: #555;'>DAY 10 FORECAST</span><br>
                    <span style='font-size: 1.3em; {d10_style}; font-weight: bold;'>{d10_val:.3f}</span>
                </div>
            </div>
            """
            st.markdown(html_card, unsafe_allow_html=True)
        else:
            st.warning("âš ï¸ æ•°æ®åº“å°šæœªæ›´æ–°ï¼Œè¯·è¿è¡Œ 'climate_collector.py' è·å–æ•°æ®ã€‚")


    # === æ ¸å¿ƒæ°”è±¡æ¿å— (4 Tabs) ===
    st.subheader("ğŸ“¡ å¤§æ°”é¥ç›¸å…³æœºåˆ¶ (Atmospheric Teleconnections)")
    st.caption("æ³¨ï¼šå›¾è¡¨å±•ç¤º GEFS é›†åˆé¢„æŠ¥å‘æ•£åº¦ã€‚çº¢çº¿ (Mean) ä»£è¡¨ä¸»æµè¶‹åŠ¿ã€‚")

    tab_nao, tab_ao, tab_pna, tab_enso = st.tabs([
        "1. åŒ—å¤§è¥¿æ´‹æ¶›åŠ¨ (NAO)", "2. åŒ—ææ¶›åŠ¨ (AO)", "3. å¤ªå¹³æ´‹-åŒ—ç¾æ¨¡å¼ (PNA)", "ğŸŒŠ NOAA ENSO å‘¨æŠ¥"
    ])

    with tab_nao:
        col_img, col_content = st.columns([1, 1.5])
        with col_img: clickable_image_html(IMG_URLS["NAO"], "NAO")
        with col_content:
            st.markdown("<div class='tag-minus'>ğŸ“‰ è´Ÿç›¸ä½ / Negative (-)</div>", unsafe_allow_html=True)
            signal_card("é˜»å¡æ•ˆåº” (Blocking)", "è¥¿é£æ€¥æµå¼¯æ›²ï¼Œæ ¼é™µå…°é«˜å‹å½¢æˆã€‚", "å†·æ°”å›¢åœ¨ç¾ä¸œ<b>åœæ»ä¸å‰</b>ã€‚",
                        "æå¼ºåˆ©å¤š (å¯’æ½®æŒç»­)")
            display_current_index_value("NAO")

    with tab_ao:
        col_img, col_content = st.columns([1, 1.5])
        with col_img: clickable_image_html(IMG_URLS["AO"], "AO")
        with col_content:
            st.markdown("<div class='tag-minus'>ğŸ“‰ è´Ÿç›¸ä½ / Negative (-)</div>", unsafe_allow_html=True)
            signal_card("ææ¶¡å´©æºƒ (Vortex Collapse)", "æåœ°é«˜å‹æ§åˆ¶ï¼Œå†·ç©ºæ°”å—ä¸‹ã€‚", "å¹¿æ³›çš„<b>å†·ç©ºæ°”çˆ†å‘</b>ã€‚",
                        "åˆ©å¤š (å†·æºå……è¶³)")
            display_current_index_value("AO")

    with tab_pna:
        col_img, col_content = st.columns([1, 1.5])
        with col_img: clickable_image_html(IMG_URLS["PNA"], "PNA")
        with col_content:
            st.markdown("<div class='tag-plus'>ğŸ“ˆ æ­£ç›¸ä½ / Positive (+)</div>", unsafe_allow_html=True)
            signal_card("è¥¿è„Šä¸œæ§½ (Ridge-Trough)", "åŒ—ç¾è¥¿éƒ¨é«˜å‹è„Šéš†èµ·ã€‚", "å»ºç«‹<b>ç»å‘ç¯æµ</b>è¾“é€å†·ç©ºæ°”ã€‚",
                        "åˆ©å¤š (é€šé“æ‰“å¼€)")
            display_current_index_value("PNA")

    with tab_enso:
        with st.spinner("æ­£åœ¨è§£æ NOAA æœ€æ–°å‘¨æŠ¥..."):
            enso_data = get_enso_summary(IMG_URLS["LANINA"])
        st.info(f"**Current Status:** {enso_data['status']}")
        if enso_data['body']:
            for s in enso_data['body']: st.markdown(f"- {s}")
        else:
            st.warning("æœªæå–åˆ°å†…å®¹ï¼Œè¯·æ£€æŸ¥ PDFã€‚")

    # === å†³ç­–çŸ©é˜µ ===
    st.markdown("---")
    st.subheader("ğŸ¯ å®è§‚äº¤æ˜“å†³ç­–çŸ©é˜µ (Decision Matrix)")
    m1, m2, m3 = st.columns(3)

    with m1:
        st.success("ğŸ”¥ **æå¯’æ¨¡å¼ (Strong Buy)**")
        st.markdown("""<div class='decision-content'>
        <span class='decision-label'>ä¿¡å·ç»„åˆ:</span>
        <span class='tag-minus'>NAO (-)</span> + <span class='tag-minus'>AO (-)</span> + <span class='tag-plus'>PNA (+)</span>
        <span class='decision-label'>ğŸ¥¶ å¤©æ°”åæœ:</span>
        é˜»å¯’é«˜å‹ + ææ¶¡å´©æºƒ + é€šé“æ‰“å¼€ã€‚å®¾å·/ä¸œåŒ—éƒ¨é­é‡æŒç»­æ€§æš´é›ªä¸æå¯’ã€‚
        <span class='decision-label'>ğŸ’° æ“ä½œå»ºè®®:</span>
        <b>æŠ¼æ³¨ä¸Šæ¶¨:</b> ä¹°å…¥ EQT / NG Futuresã€‚
    </div>""", unsafe_allow_html=True)

    with m2:
        st.error("ğŸŸ¢ **æš–å†¬æ¨¡å¼ (Strong Sell)**")
        st.markdown("""<div class='decision-content'>
        <span class='decision-label'>ä¿¡å·ç»„åˆ:</span>
        <span class='tag-bear'>NAO (+)</span> + <span class='tag-bear'>AO (+)</span> + <span class='tag-bear'>PNA (-)</span>
        <span class='decision-label'>â˜€ï¸ å¤©æ°”åæœ:</span>
        å¼ºåŠ²è¥¿é£æ€¥æµ + ä¸œå—é«˜å‹è„Šã€‚æš–æ¹¿æ°”æµä¸»å¯¼ç¾ä¸œï¼Œä¸ä¸‹é›ªåªä¸‹é›¨ã€‚
        <span class='decision-label'>ğŸ’° æ“ä½œå»ºè®®:</span>
        <b>æŠ¼æ³¨ä¸‹è·Œ:</b> å–å‡ºèµ„äº§ / è§‚æœ›ã€‚
    </div>""", unsafe_allow_html=True)

    with m3:
        st.warning("âš–ï¸ **éœ‡è¡æ¨¡å¼ (Neutral)**")
        st.markdown("""<div class='decision-content'>
        <span class='decision-label'>ä¿¡å·ç»„åˆ:</span>
        <span class='tag-neutral'>ä¿¡å·èƒŒç¦» (Mixed)</span>
        <span class='decision-label'>ğŸ’¨ å¤©æ°”åæœ:</span>
        å†·æºå……è¶³ä½†ç¼ºä¹é˜»å¡ã€‚å¯’æ½®æ¥å»åŒ†åŒ†ï¼Œæ°”æ¸©å¿½å†·å¿½çƒ­ã€‚
        <span class='decision-label'>ğŸ’° æ“ä½œå»ºè®®:</span>
        <b>æ³¢æ®µæ“ä½œ:</b> ä¸è¦é•¿æœŸæŒæœ‰ã€‚
    </div>""", unsafe_allow_html=True)

    # === åœ°å­¦åŸç† ===
    st.markdown("---")
    st.subheader("ğŸ“š Geophysical Fluid Dynamics & Market Mapping")
    with st.expander("ğŸ“– ç‚¹å‡»å±•å¼€ï¼šè¯¦ç»†é€»è¾‘é“¾æ¡æ¨æ¼” (Logic Chain Analysis)", expanded=True):
        st.markdown("#### 1. North Atlantic Oscillation (NAO)")
        st.markdown(
            "* **Phenomenon:** Significant **Positive Geopotential Height Anomalies** over Greenland.\n"
            "* **Logic Chain:** <span class='tag-minus'>Negative (-)</span> NAO $\\rightarrow$ Traffic Jam for Weather Systems $\\rightarrow$ **Cold Air Stagnation**.",
            unsafe_allow_html=True)
        st.markdown("#### 2. Arctic Oscillation (AO)")
        st.markdown(
            "* **Phenomenon:** Rise in Sea Level Pressure (SLP) over the Arctic Cap.\n"
            "* **Logic Chain:** <span class='tag-minus'>Negative (-)</span> AO $\\rightarrow$ **Meridional Spillover** of Arctic Air $\\rightarrow$ High Heating Demand.",
            unsafe_allow_html=True)
        st.markdown("#### 3. Pacific-North American (PNA)")
        st.markdown(
            "* **Phenomenon:** Quadripole pressure anomaly pattern.\n"
            "* **Logic Chain:** <span class='tag-plus'>Positive (+)</span> PNA $\\rightarrow$ NW-to-SE Flow Vector $\\rightarrow$ **Targeted Delivery** of cold air.",
            unsafe_allow_html=True)

else:
    # ==========================================
    # ğŸ“… å†å²æ•°æ®å›æº¯åˆ†ææ¨¡å¼ (History)
    # ==========================================
    st.title("ğŸ“… å†å²æ•°æ®åº“ (Historical Data Archive)")

    tab_hist_weather, tab_hist_hdd, tab_hist_eia = st.tabs(["â˜ï¸ æ°”è±¡ (Weather)", "ğŸ”¥ éœ€æ±‚ (HDD)", "ğŸ¦ åº“å­˜ (EIA)"])


    # === è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–æ—¥æœŸåˆ— ===
    def format_date_cols(df):
        for col in ["Run_Date", "Source_Date", "Report_Date", "Date"]:
            if col in df.columns:
                try:
                    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')
                except:
                    pass
        return df


    # === è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾æ—¥æœŸåˆ— ===
    def get_date_col(df):
        for col in ["Report_Date", "Run_Date", "Date", "date", "Timestamp"]:
            if col in df.columns: return col
        return None


    # --- 1. æ°”è±¡å†å² (ä¿æŒä¸‰å¡”å¸ƒå±€) ---
    with tab_hist_weather:
        st.markdown("### ğŸ“¡ é¥ç›¸å…³è¶‹åŠ¿è¿½è¸ª")
        if os.path.exists("history_weather.csv"):
            try:
                df = pd.read_csv("history_weather.csv")
                date_col = get_date_col(df)
                if date_col:
                    df = df.sort_values(date_col, ascending=False)
                    df = format_date_cols(df)
                    df = df.set_index(date_col)
                    df.index.name = "Run Date"


                    def get_cols(prefix):
                        target = [f"{prefix}_Obs", f"{prefix}_Day7", f"{prefix}_Day10"]
                        rename_map = {f"{prefix}_Obs": "Obs", f"{prefix}_Day7": "Day 7", f"{prefix}_Day10": "Day 10"}
                        available = [c for c in target if c in df.columns]
                        return df[available].rename(columns=rename_map)


                    df_ao, df_nao, df_pna = get_cols("AO"), get_cols("NAO"), get_cols("PNA")


                    def style_ao_nao(val):
                        if pd.isna(val): return ''
                        if val < 0: return 'color: #2e7d32; background-color: #e8f5e9; font-weight: bold'
                        if val > 0: return 'color: #c62828; background-color: #ffebee'
                        return ''


                    def style_pna(val):
                        if pd.isna(val): return ''
                        if val > 0: return 'color: #2e7d32; background-color: #e8f5e9; font-weight: bold'
                        if val < 0: return 'color: #c62828; background-color: #ffebee'
                        return ''


                    c1, c2, c3 = st.columns([1.3, 1, 1])
                    with c1:
                        st.markdown("##### AO"); st.dataframe(df_ao.style.format("{:.2f}").applymap(style_ao_nao),
                                                                 width='stretch', height=500)
                    with c2:
                        st.markdown("##### NAO"); st.dataframe(df_nao.style.format("{:.2f}").applymap(style_ao_nao),
                                                                 width='stretch', hide_index=True, height=500)
                    with c3:
                        st.markdown("##### PNA"); st.dataframe(df_pna.style.format("{:.2f}").applymap(style_pna),
                                                                  width='stretch', hide_index=True, height=500)
                else:
                    st.warning("æ•°æ®å¼‚å¸¸")
            except:
                st.info("æš‚æ— æ•°æ®")
        else:
            st.info("æš‚æ— æ•°æ®")

    # --- 2. HDD å†å² (ç¾ä¸œè¡¥å…¨ Act/Dev/YoY) ---
    with tab_hist_hdd:
        st.markdown("### ğŸ”¥ åŒºåŸŸéœ€æ±‚å…¨è§ˆ (HDD)")
        st.caption("Act:å®é™… | Dev:è·å¹³ | YoY:åŒæ¯”")

        if os.path.exists("history_hdd.csv"):
            try:
                df = pd.read_csv("history_hdd.csv")
                if "Run_Date" in df.columns:
                    df = df.sort_values("Run_Date", ascending=False)
                    df = format_date_cols(df)

                # (A) ç¾ä¸œ (East) - æœ€å…¨æ•°æ®
                # æ„é€ ç›®æ ‡åˆ—
                rename_east = {
                    "Run_Date": "Run Date", "Source_Date": "Source",
                    "NE_Actual": "NE Act", "NE_Dev_Norm": "NE Dev", "NE_Dev_Year": "NE YoY",
                    "MA_Actual": "MA Act", "MA_Dev_Norm": "MA Dev", "MA_Dev_Year": "MA YoY"
                }
                # è¿‡æ»¤å­˜åœ¨çš„åˆ—
                valid_east = [c for c in rename_east.keys() if c in df.columns]
                df_east = df[valid_east].rename(columns=rename_east)
                if "Run Date" in df_east.columns: df_east = df_east.set_index("Run Date")

                # (B) ä¸­è¥¿éƒ¨
                df_mw = df[["MW_Actual", "MW_Dev_Norm", "MW_Dev_Year"]].rename(
                    columns={"MW_Actual": "Act", "MW_Dev_Norm": "Dev", "MW_Dev_Year": "YoY"})

                # (C) å…¨ç¾
                df_us = df[["US_Actual", "US_Dev_Norm", "US_Dev_Year"]].rename(
                    columns={"US_Actual": "Act", "US_Dev_Norm": "Dev", "US_Dev_Year": "YoY"})


                def style_hdd(val):
                    if pd.isna(val): return ''
                    if isinstance(val, (int, float)):
                        if val > 0: return 'color: #2e7d32; font-weight: bold; background-color: #e8f5e9'
                        if val < 0: return 'color: #c62828; font-weight: bold; background-color: #ffebee'
                    return ''


                c1, c2, c3 = st.columns([2.3, 1, 1])
                with c1:
                    st.markdown("**ğŸ™ ç¾ä¸œ (East)**")
                    # æ‰¾å‡ºæ•°å­—åˆ—è¿›è¡Œæ ¼å¼åŒ–
                    num_cols = [c for c in df_east.columns if "Act" in c or "Dev" in c or "YoY" in c]
                    color_cols = [c for c in df_east.columns if "Dev" in c or "YoY" in c]
                    st.dataframe(df_east.style.format("{:.0f}", subset=num_cols).applymap(style_hdd, subset=color_cols),
                                 width='stretch')
                with c2:
                    st.markdown("**ğŸ­ ä¸­è¥¿éƒ¨ (Midwest)**")
                    st.dataframe(df_mw.style.format("{:.0f}").applymap(style_hdd, subset=["Dev", "YoY"]),
                                 width='stretch', hide_index=True)
                with c3:
                    st.markdown("**ğŸ‡ºğŸ‡¸ å…¨ç¾ (US Total)**")
                    st.dataframe(df_us.style.format("{:.0f}").applymap(style_hdd, subset=["Dev", "YoY"]),
                                 width='stretch', hide_index=True)
            except Exception as e:
                st.error(f"Error: {e}")
        else:
            st.info("æš‚æ— æ•°æ®")

    # --- 3. EIA å†å² (æ¢å¤ 6åˆ—Ã—4åŒº å…¨ç»´åº¦å¸ƒå±€) ---
    with tab_hist_eia:
        st.markdown("### ğŸ¦ åº“å­˜å…¨æ™¯ (Detailed Storage Report)")

        if os.path.exists("history_storage.csv"):
            try:
                df = pd.read_csv("history_storage.csv")
                date_col = "Report_Date" if "Report_Date" in df.columns else get_date_col(df)

                if date_col in df.columns:
                    df = df.sort_values(date_col, ascending=False)

                    # === 1. å®šä¹‰æ˜¾ç¤ºé¡ºåº (Total -> East -> Midwest -> SouthCentral) ===
                    # ä¸¥æ ¼æŒ‰ç…§æ‚¨çš„è¦æ±‚æ’åº
                    regions_order = [
                        ("Total", "Total 48"),
                        ("East", "East"),
                        ("Midwest", "Midwest"),
                        ("SouthCentral", "S.Central")
                    ]

                    final_data = {}

                    # === 2. éå†å¹¶è®¡ç®— 6 ä¸ªæŒ‡æ ‡ ===
                    for prefix, display_name in regions_order:
                        col_stock = f"{prefix}_Stock"
                        col_net = f"{prefix}_Net_Change"
                        col_y_ago = f"{prefix}_Year_Ago"
                        col_5_avg = f"{prefix}_5Yr_Avg"

                        if col_stock not in df.columns: continue

                        # 1. Stock
                        final_data[(display_name, "Stock")] = df[col_stock]

                        # 2. Net Chg
                        if col_net in df.columns:
                            final_data[(display_name, "Net Chg")] = df[col_net]

                        # 3. Year Ago
                        if col_y_ago in df.columns:
                            final_data[(display_name, "Year Ago")] = df[col_y_ago]
                            # 4. vs Year %
                            final_data[(display_name, "vs Year %")] = ((df[col_stock] - df[col_y_ago]) / df[
                                col_y_ago]) * 100

                        # 5. 5-Yr Avg
                        if col_5_avg in df.columns:
                            final_data[(display_name, "5-Yr Avg")] = df[col_5_avg]
                            # 6. vs 5Yr %
                            final_data[(display_name, "vs 5Yr %")] = ((df[col_stock] - df[col_5_avg]) / df[
                                col_5_avg]) * 100

                    # === 3. æ„å»º DataFrame ===
                    view_df = pd.DataFrame(final_data)
                    try:
                        view_df.index = pd.to_datetime(df[date_col]).dt.strftime('%Y-%m-%d')
                    except:
                        view_df.index = df[date_col]
                    view_df.index.name = "Report Date"


                    # === 4. æ ·å¼é€»è¾‘ (å¤åˆ»æˆªå›¾) ===
                    # é¢œè‰²ï¼šè´Ÿç»¿æ­£çº¢
                    def style_color(v):
                        if pd.isna(v): return ''
                        if v < 0: return 'color: #2e7d32; font-weight: bold;'
                        if v > 0: return 'color: #c62828; font-weight: bold;'
                        return 'color: black;'


                    # èƒŒæ™¯ï¼šæµ…é»„
                    def style_bg(v):
                        return 'background-color: #fff3cd;'


                    styler = view_df.style
                    all_cols = view_df.columns

                    # æ ¼å¼åŒ–: æ•´æ•°
                    int_cols = [c for c in all_cols if c[1] in ["Stock", "Year Ago", "5-Yr Avg"]]
                    styler = styler.format("{:,.0f}", subset=int_cols)

                    # æ ¼å¼åŒ–: å¸¦ç¬¦å·æ•´æ•°
                    net_cols = [c for c in all_cols if c[1] == "Net Chg"]
                    styler = styler.format("{:+.0f}", subset=net_cols)

                    # æ ¼å¼åŒ–: ç™¾åˆ†æ¯”
                    pct_cols = [c for c in all_cols if "%" in c[1]]
                    styler = styler.format("{:+.1f}", subset=pct_cols)

                    # åº”ç”¨æ ·å¼ (åªç»™ Net å’Œ % ä¸Šè‰²å’ŒèƒŒæ™¯)
                    target_cols = net_cols + pct_cols
                    styler = styler.applymap(style_color, subset=target_cols)
                    styler = styler.applymap(style_bg, subset=target_cols)

                    styler = styler.set_properties(**{'text-align': 'center'})

                    st.dataframe(styler, width='stretch', height=600)

                else:
                    st.warning("æ•°æ®å¼‚å¸¸ï¼šç¼ºå¤± Report_Date")
            except Exception as e:
                st.error(f"Error: {e}")
        else:
            st.info("æš‚æ— æ•°æ®")
